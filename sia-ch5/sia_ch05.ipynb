{"cells":[{"cell_type":"code","source":["dbutils.fs.ls('/FileStore/tables/pc5ly1131502251351157/italianPosts.csv')"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":["#### italianPosts.csv\n1. commentCount—Number of comments related to the question/answer\n1. lastActivityDate—Date and time of the last modification\n1. ownerUserId—User ID of the owner\n1. body—Textual contents of the question/answer\n1. score—Total score based on upvotes and downvotes\n1. creationDate—Date and time of creation\n1. viewCount—View count\n1. title—Title of the question\n1. tags—Set of tags the question has been marked with\n1. answerCount—Number of related answers\n1. acceptedAnswerId—If a question contains the ID of its accepted answer\n1. postTypeId—Type of the post; 1 is for questions, 2 for answers\n1. id—Post’s unique ID"],"metadata":{}},{"cell_type":"code","source":["# load into rdd\nrddItalianPosts_1 = sc.textFile('/FileStore/tables/pc5ly1131502251351157/italianPosts.csv') \\\n                    .map(lambda line: line.split('~'))\nrddItalianPosts_1.count()\nrddItalianPosts_1.take(1)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["#### 5.1.1\n#### Creating a DataFrame from an RDD of tuples"],"metadata":{}},{"cell_type":"code","source":["# convert each RDD array to tuple\nrddItalianPosts_2 = rddItalianPosts_1.map(lambda l: (l[0], l[1], l[2], l[3], l[4], l[5], l[6], l[7], l[8], l[9], l[10], l[11], l[12]))\nrddItalianPosts_2.take(1)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# now convert to DF\ndfItalianPosts = rddItalianPosts_2.toDF(['commentCount', 'lastActivityDate', 'ownerUserId', 'body', 'score', 'creationDate', 'viewCount', 'title', 'tags', 'answerCount', 'acceptedAnswerId', 'postTypeId', 'id'])\ndfItalianPosts.show(2)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["##### Note that the field data type are incorrect"],"metadata":{}},{"cell_type":"code","source":["dfItalianPosts.printSchema()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["We'll need to define schema manually to set the proper datatypes"],"metadata":{}},{"cell_type":"markdown","source":["#### Converting RDDs to DataFrames by specifying a schema"],"metadata":{}},{"cell_type":"code","source":["from datetime import datetime\n\ndef toIntSafe(val):\n  try:\n    return int(val)\n  except ValueError:\n    return None\n  \ndef toLongSafe(val):\n  try:\n    return long(val)\n  except ValueError:\n    return None\n  \ndef toTimeSafe(val):\n  try:\n    return datetime.strptime(val, \"%Y-%m-%d %H:%M:%S.%f\")\n  except ValueError:\n    return None\n  \n# Method to convert string to a Row\nfrom pyspark.sql import Row\ndef stringToPost(string):\n  l_s = string.encode('utf8').strip().split('~')\n  return Row(\n    toIntSafe(l_s[0]),   # commentCount\n    toTimeSafe(l_s[1]),  # lastActivityDate\n    toLongSafe(l_s[2]),  # ownerUserId\n    l_s[3],              # body\n    toIntSafe(l_s[4]),   # score\n    toTimeSafe(l_s[5]),  # creationDate\n    toIntSafe(l_s[6]),   # viewCount\n    l_s[7],              # title\n    l_s[8],              # tags\n    toIntSafe(l_s[9]),   # answerCount\n    toLongSafe(l_s[10]), # acceptedAnswerId\n    toLongSafe(l_s[11]), # postTypeId\n    toLongSafe(l_s[12]), # id\n  )\n  \n# Define schema\nfrom pyspark.sql.types import *\npostSchema = StructType([\n    StructField('commentCount', IntegerType(), True),\n    StructField('lastActivityDate', TimestampType(), True),\n    StructField('ownerUserId', LongType(), True),\n    StructField('body', StringType(), True),\n    StructField('score', IntegerType(), True),\n    StructField('creationDate', TimestampType(), True),\n    StructField('viewCount', IntegerType(), True),\n    StructField('title', StringType(), True),\n    StructField('tags', StringType(), True),\n    StructField('answerCount', IntegerType(), True),\n    StructField('acceptedAnswerId', LongType(), True),\n    StructField('postTypeId', LongType(), True),\n    StructField('id', LongType(), False),\n  ])"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# Now, create RDD using schema\nrddItalianPosts_3 = sc.textFile('/FileStore/tables/pc5ly1131502251351157/italianPosts.csv') \\\n                      .map(lambda line: stringToPost(line))\nrddItalianPosts_3.count()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["dfItalianPosts_1 = sqlContext.createDataFrame(rddItalianPosts_3, schema=postSchema)\ndfItalianPosts_1.take(1)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["dfItalianPosts_1.printSchema()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["dfItalianPosts_1.columns"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["dfItalianPosts_1.dtypes"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":17}],"metadata":{"name":"sia-ch05","notebookId":46921479939159},"nbformat":4,"nbformat_minor":0}
